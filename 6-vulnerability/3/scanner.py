import requests
import re
from urllib.parse import urljoin

class Scanner:
    def __init__(self, target_url, links_to_ignore):
        self.target_url = target_url
        self.links_to_ignore = links_to_ignore
        self.visited_links = set()
        self.paths = []

        self.session = requests.Session()

    def extract_links_from(self, url):
        try:
            response = self.session.get(url)
            response.raise_for_status()
            return re.findall('(?:href=")(.*?)"', response.text)
        except requests.RequestException:
            return []

    def crawl(self):
        href_links = self.extract_links_from(self.target_url)
        for link in href_links:
            absolute_link = urljoin(self.target_url, link)
            if absolute_link not in self.visited_links and absolute_link not in self.links_to_ignore:
                self.visited_links.add(absolute_link)
                self.paths.append(absolute_link)
                print(absolute_link)
                self.crawl()

    def run_scanner(self):
        print("Scanning...")
        for path in self.paths:
            response = self.session.get(path)
            # Perform vulnerability checks on the response
            # and print the results accordingly


# Define the target URL and links to ignore
target_url = "http://192.168.187.134/dvwa/"
links_to_ignore = ["http://192.168.187.134/dvwa/logout.php"]

# Define the login credentials
data_dict = {"username": "admin", "password": "password", "Login": "submit"}

# Instantiate the Scanner class
vuln_scanner = Scanner(target_url, links_to_ignore)

# Login to the application
vuln_scanner.session.post(target_url + "login.php", data=data_dict)

# Crawl the target URL
vuln_scanner.crawl()

# Run the scanner
vuln_scanner.run_scanner()
