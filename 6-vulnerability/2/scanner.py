import requests
import re
from urllib.parse import urljoin

class Scanner:
    def __init__(self):
        self.visited_links = set()
        self.paths = set()

    def extract_links_from(self, url):
        try:
            response = requests.get(url)
            response.raise_for_status()
            return re.findall('(?:href=")(.*?)"', response.text)
        except (requests.RequestException, UnicodeDecodeError):
            return []

    def crawl(self, target_url):
        href_links = self.extract_links_from(target_url)
        for link in href_links:
            absolute_link = urljoin(target_url, link)
            if absolute_link.startswith(target_url):
                if absolute_link not in self.visited_links:
                    self.visited_links.add(absolute_link)
                    self.paths.add(absolute_link)
                    print(absolute_link)
                    self.crawl(absolute_link)
